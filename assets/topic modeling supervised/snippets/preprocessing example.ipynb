{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMJUx7fHS5/Sptpv3SQfswD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Text preprocessing to reduce the dimension of the Document-Term matrix (DTM)"],"metadata":{"id":"GffknP85cyQ9"}},{"cell_type":"markdown","source":["Imports"],"metadata":{"id":"D7feDioZc12p"}},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer"],"metadata":{"id":"mrroxPzUc2uX","executionInfo":{"status":"ok","timestamp":1729437018957,"user_tz":-180,"elapsed":279,"user":{"displayName":"Digital Linguistics","userId":"01161764287296347576"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["Given two documents in the Russian language"],"metadata":{"id":"fGELzNN9ercD"}},{"cell_type":"code","source":["documents = [\n","    \"Я люблю свою собаку.\",\n","    \"своя собака меня любит.\"\n","]"],"metadata":{"id":"nN7eUsklev0z","executionInfo":{"status":"ok","timestamp":1729437574271,"user_tz":-180,"elapsed":331,"user":{"displayName":"Digital Linguistics","userId":"01161764287296347576"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["When we construct the DTM the inflected word forms are considered as unique words"],"metadata":{"id":"bEkERA8gez8F"}},{"cell_type":"code","source":["vectorizer = TfidfVectorizer()\n","\n","dtm = vectorizer.fit_transform(documents)\n","\n","dtm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F_6yytshe2iw","executionInfo":{"status":"ok","timestamp":1729437731797,"user_tz":-180,"elapsed":262,"user":{"displayName":"Digital Linguistics","userId":"01161764287296347576"}},"outputId":"57e9198a-f85f-4c15-bd71-5a2fad6278ef"},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<2x7 sparse matrix of type '<class 'numpy.float64'>'\n","\twith 7 stored elements in Compressed Sparse Row format>"]},"metadata":{},"execution_count":35}]},{"cell_type":"markdown","source":["Let's check the unique word forms identified by the vectorizer"],"metadata":{"id":"Kr2WeqYYhT3d"}},{"cell_type":"code","source":["vectorizer.get_feature_names_out()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j5-P5wADhV2i","executionInfo":{"status":"ok","timestamp":1729437722090,"user_tz":-180,"elapsed":429,"user":{"displayName":"Digital Linguistics","userId":"01161764287296347576"}},"outputId":"695d1ef4-2c4d-4618-b641-f8fcf06b39b7"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['любит', 'люблю', 'меня', 'свою', 'своя', 'собака', 'собаку'],\n","      dtype=object)"]},"metadata":{},"execution_count":34}]},{"cell_type":"markdown","source":["We can reduce the number of terms (the size of the vocabulary) by performing text preprocessing with the help of spaCy.\n","\n","First, we need to download a SpaCy language model for Russian."],"metadata":{"id":"w_5jzaexdJ3H"}},{"cell_type":"code","source":["!python -m spacy download ru_core_news_sm -q\n","\n","import spacy\n","\n","nlp = spacy.load(\"ru_core_news_sm\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jAtryPTTdNjD","executionInfo":{"status":"ok","timestamp":1729437591624,"user_tz":-180,"elapsed":11471,"user":{"displayName":"Digital Linguistics","userId":"01161764287296347576"}},"outputId":"c8251b6a-e76b-4ac2-9a02-8e051bf5bdbb"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('ru_core_news_sm')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n"]}]},{"cell_type":"markdown","source":["Let's define a text preprocessing function using spaCy"],"metadata":{"id":"XkQkjPwRdaL9"}},{"cell_type":"code","source":["def spacy_preprocessor(text):\n","  doc = nlp(text)\n","  return \" \".join([\n","      token.lemma_              # use the lemmatized form\n","      for token in doc\n","      if not token.is_stop      # exclude stop words\n","      and not token.is_punct    # exclude punctuation\n","      ])"],"metadata":{"id":"DrkZ4gJ0ddgb","executionInfo":{"status":"ok","timestamp":1729437596292,"user_tz":-180,"elapsed":293,"user":{"displayName":"Digital Linguistics","userId":"01161764287296347576"}}},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":["Now we can pass the text preprocessing function as argument when creating the vectorizer object."],"metadata":{"id":"C5zx-CjqdsD_"}},{"cell_type":"code","source":["custom_vectorizer = TfidfVectorizer(preprocessor=spacy_preprocessor)\n","\n","new_dtm = custom_vectorizer.fit_transform(documents)\n","\n","new_dtm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UOQBD8hfdqwY","executionInfo":{"status":"ok","timestamp":1729437663245,"user_tz":-180,"elapsed":271,"user":{"displayName":"Digital Linguistics","userId":"01161764287296347576"}},"outputId":"1d7fa5bd-f3aa-4da0-f37e-39b12a2dde7b"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<2x2 sparse matrix of type '<class 'numpy.float64'>'\n","\twith 4 stored elements in Compressed Sparse Row format>"]},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","source":["Let's check the unique word forms identified by the custom vectorizer"],"metadata":{"id":"3zwy7MhchI-j"}},{"cell_type":"code","source":["custom_vectorizer.get_feature_names_out()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PBNlsL7-hG1T","executionInfo":{"status":"ok","timestamp":1729437683164,"user_tz":-180,"elapsed":402,"user":{"displayName":"Digital Linguistics","userId":"01161764287296347576"}},"outputId":"e217630d-e3ee-40e6-8f1b-d1b448aa78e2"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['любить', 'собака'], dtype=object)"]},"metadata":{},"execution_count":33}]},{"cell_type":"markdown","source":["## The applied function helped us reduce the vocabulary size"],"metadata":{"id":"8opxz9uvheJA"}}]}